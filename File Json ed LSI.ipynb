{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questo programma è in grado di avviare una procedura di LSI:\n",
    "# - Prendo un file .json e lo importo\n",
    "# - Costruisco una collection di documenti \n",
    "# - Infine la analizzo enucleando 2 concetti di 10 parole ciascuno (volendo potrei cambiarlo ovviamente)\n",
    "# - Salvo il risultato su un file di output\n",
    "\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import json\n",
    "\n",
    "# Il codice json serve per l'LDA\n",
    "# La collection di documenti per l'LSI è costituito dall'insieme dei topic estratti con l'LDA\n",
    "# Bisogna fare la pulitura del testo...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il file deve essere in formato .txt!!!\n",
    "data = []\n",
    "with open('C:/Users/Davide/Sample.txt') as f: # Sostituire il percorso quando si cambia location\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=2, n_iter=1000,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_testi = []\n",
    "for i in range(0, len(data)):  \n",
    "    collection_testi.append(str(data[i]['title']) + str(data[i]['text']) + str(data[i]['tags']) + str(data[i]['resume']))\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(collection_testi)\n",
    "\n",
    "lsa = TruncatedSVD(n_components = 2, n_iter = 1000) # Qual è il numero più corretto di componenti???\n",
    "lsa.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "out = []\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    termsInComp = zip(terms,comp)\n",
    "    sortedTerms = sorted(termsInComp, key=lambda x: x[1], reverse=True ) [:10]\n",
    "    string = ''\n",
    "    \n",
    "    for term in sortedTerms:\n",
    "        string = string + ' ' + term[0]\n",
    "    out.append(string)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio\n",
    "with open(\"Output News.txt\", \"w\") as output:\n",
    "    output.write(\"\\n\".join(map(lambda x: str(x), out)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
